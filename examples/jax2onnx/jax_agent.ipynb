{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdfa3eb4-1758-4634-b398-cdc3c4c5d7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example successfully demonstrates the conversion of JAX functions to TensorFlow and subsequently to ONNX, \n",
    "# using TensorFlow's tf2onnx tool for ONNX export and ONNX Runtime for inference. \n",
    "\n",
    "from jax.experimental import jax2tf\n",
    "from jax import numpy as jnp\n",
    "from jax import tree_util as jtu, vmap, jit, lax, nn\n",
    "from jax.experimental import sparse\n",
    "\n",
    "from pymdp.jax.agent import Agent\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from functools import partial\n",
    "from typing import Optional, Tuple, List\n",
    "import time\n",
    "\n",
    "import onnx\n",
    "import tf2onnx\n",
    "import onnxruntime as ort\n",
    "from onnxsim import simplify\n",
    "import netron\n",
    "\n",
    "from opt_einsum import contract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13139359-e3a6-4b38-833c-b52df818ff8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MINVAL = jnp.finfo(float).eps\n",
    "\n",
    "def log_stable(x):\n",
    "    return jnp.log(jnp.clip(x, min=MINVAL))\n",
    "\n",
    "@partial(jit, static_argnames=['keep_dims'])\n",
    "def factor_dot(M, xs, keep_dims: Optional[Tuple[int]] = None):\n",
    "    \"\"\" Dot product of a multidimensional array with `x`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    - `qs` [list of 1D numpy.ndarray] - list of jnp.ndarrays\n",
    "    \n",
    "    Returns \n",
    "    -------\n",
    "    - `Y` [1D numpy.ndarray] - the result of the dot product\n",
    "    \"\"\"\n",
    "    d = len(keep_dims) if keep_dims is not None else 0\n",
    "    assert M.ndim == len(xs) + d\n",
    "    keep_dims = () if keep_dims is None else keep_dims\n",
    "    dims = tuple((i,) for i in range(M.ndim) if i not in keep_dims)\n",
    "    return factor_dot_flex(M, xs, dims, keep_dims=keep_dims)\n",
    "\n",
    "@partial(jit, static_argnames=['dims', 'keep_dims'])\n",
    "def factor_dot_flex(M, xs, dims: List[Tuple[int]], keep_dims: Optional[Tuple[int]] = None):\n",
    "    \"\"\" Dot product of a multidimensional array with `x`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    - `M` [numpy.ndarray] - tensor\n",
    "    - 'xs' [list of numpyr.ndarray] - list of tensors\n",
    "    - 'dims' [list of tuples] - list of dimensions of xs tensors in tensor M\n",
    "    - 'keep_dims' [tuple] - tuple of integers denoting dimesions to keep\n",
    "    Returns \n",
    "    -------\n",
    "    - `Y` [1D numpy.ndarray] - the result of the dot product\n",
    "    \"\"\"\n",
    "    all_dims = tuple(range(M.ndim))\n",
    "    matrix = [[xs[f], dims[f]] for f in range(len(xs))]\n",
    "    args = [M, all_dims]\n",
    "    for row in matrix:\n",
    "        args.extend(row)\n",
    "\n",
    "    args += [keep_dims]\n",
    "    return contract(*args, backend='jax')\n",
    "\n",
    "def get_likelihood_single_modality(o_m, A_m, distr_obs=True):\n",
    "    \"\"\"Return observation likelihood for a single observation modality m\"\"\"\n",
    "    if distr_obs:\n",
    "        expanded_obs = jnp.expand_dims(o_m, tuple(range(1, A_m.ndim)))\n",
    "        likelihood = (expanded_obs * A_m).sum(axis=0)\n",
    "    else:\n",
    "        likelihood = A_m[o_m]\n",
    "\n",
    "    return likelihood\n",
    "\n",
    "def compute_log_likelihood_single_modality(o_m, A_m, distr_obs=True):\n",
    "    \"\"\"Compute observation log-likelihood for a single modality\"\"\"\n",
    "    return log_stable(get_likelihood_single_modality(o_m, A_m, distr_obs=distr_obs))\n",
    "\n",
    "def compute_log_likelihood_per_modality(obs, A, distr_obs=True):\n",
    "    \"\"\" Compute likelihood over hidden states across observations from different modalities, and return them per modality \"\"\"\n",
    "    ll_all = jtu.tree_map(lambda o, a: compute_log_likelihood_single_modality(o, a, distr_obs=distr_obs), obs, A)\n",
    "\n",
    "    return ll_all\n",
    "    \n",
    "def marginal_log_likelihood(qs, log_likelihood, i):\n",
    "    #print(\"thereee\", log_likelihood.shape)\n",
    "    xs = [q for j, q in enumerate(qs) if j != i]\n",
    "    return factor_dot(log_likelihood, xs, keep_dims=(i,))\n",
    "\n",
    "def mll_factors(qs, ll_m, factor_list_m) -> List:\n",
    "    factor_list_m = [0,1]\n",
    "    relevant_factors = [qs[f] for f in factor_list_m]\n",
    "    marginal_ll_f = jtu.Partial(marginal_log_likelihood, relevant_factors, ll_m)\n",
    "    loc_nf = len(factor_list_m)\n",
    "    loc_factors = list(range(loc_nf))\n",
    "    return jtu.tree_map(marginal_ll_f, loc_factors)\n",
    "\n",
    "def all_marginal_log_likelihood(qs, log_likelihoods, all_factor_lists):\n",
    "    qL_marginals = jtu.tree_map(lambda ll_m, factor_list_m: mll_factors(qs, ll_m, factor_list_m), log_likelihoods, all_factor_lists)\n",
    "    num_factors = len(qs)\n",
    "\n",
    "    # instead of a double loop we could have a list defining m to f mapping\n",
    "    # which could be resolved with a single tree_map cast\n",
    "    qL_all = [jnp.zeros(1)] * num_factors\n",
    "    for m, factor_list_m in enumerate(all_factor_lists):\n",
    "        factor_list_m = [0, 1]\n",
    "        for l, f in enumerate(factor_list_m):\n",
    "            qL_all[f] += qL_marginals[m][l]\n",
    "\n",
    "    return qL_all\n",
    "\n",
    "def add(x, y):\n",
    "    return x + y\n",
    "\n",
    "xs = jnp.arange(16)\n",
    "\n",
    "def run_factorized_fpi(A, obs, prior, A_dependencies, num_iter=1):\n",
    "    \"\"\"\n",
    "    Run the fixed point iteration algorithm with sparse dependencies between factors and outcomes (stored in `A_dependencies`)\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Compute log likelihoods for each factor\n",
    "    log_likelihoods = compute_log_likelihood_per_modality(obs, A)\n",
    "\n",
    "    # Step 2: Map prior to log space and create initial log-posterior\n",
    "    log_prior = jtu.tree_map(log_stable, prior)\n",
    "    log_q = jtu.tree_map(jnp.zeros_like, prior)\n",
    "\n",
    "    # Step 3: Iterate until convergence\n",
    "    def scan_fn(carry, t):\n",
    "        log_q = carry\n",
    "        q = jtu.tree_map(nn.softmax, log_q)\n",
    "        marginal_ll = all_marginal_log_likelihood(q, log_likelihoods, A_dependencies)\n",
    "        log_q = jtu.tree_map(add, marginal_ll, log_prior)\n",
    "\n",
    "        return log_q, None\n",
    "\n",
    "    res, _ = lax.scan(scan_fn, log_q, xs)\n",
    "\n",
    "    # Step 4: Map result to factorised posterior\n",
    "    qs = jtu.tree_map(nn.softmax, res)\n",
    "    return qs\n",
    "\n",
    "def top_function(A, obs, prior, A_dependencies, num_iter=16):\n",
    "    infer_states = partial(\n",
    "        run_factorized_fpi,\n",
    "        A_dependencies=A_dependencies,\n",
    "        num_iter=num_iter\n",
    "    )\n",
    "    \n",
    "    output = vmap(infer_states)(\n",
    "        A,\n",
    "        obs,\n",
    "        prior\n",
    "    )\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5015113c-f836-4113-a210-c1754961c351",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs\n",
      "A [Array([[[[1. , 1. ],\n",
      "         [1. , 1. ],\n",
      "         [0.5, 1. ]],\n",
      "\n",
      "        [[0. , 0. ],\n",
      "         [0. , 0. ],\n",
      "         [0.5, 0. ]]],\n",
      "\n",
      "\n",
      "       [[[1. , 1. ],\n",
      "         [1. , 1. ],\n",
      "         [0.5, 1. ]],\n",
      "\n",
      "        [[0. , 0. ],\n",
      "         [0. , 0. ],\n",
      "         [0.5, 0. ]]]], dtype=float32)]\n",
      "obs [Array([[1., 0.],\n",
      "       [1., 0.]], dtype=float32)]\n",
      "D [Array([[0.33333334, 0.33333334, 0.33333334],\n",
      "       [0.33333334, 0.33333334, 0.33333334]], dtype=float32), Array([[0.5, 0.5],\n",
      "       [0.5, 0.5]], dtype=float32)]\n",
      "A_dep [[0, 1]]\n",
      "output\n",
      "[Array([[0.36628395, 0.36628395, 0.2674321 ],\n",
      "       [0.36628395, 0.36628395, 0.2674321 ]], dtype=float32), Array([[0.45378983, 0.5462102 ],\n",
      "       [0.45378983, 0.5462102 ]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "num_states = [3, 2]\n",
    "num_obs = [2]\n",
    "n_batch = 2\n",
    "\n",
    "A_1 = jnp.array([[1.0, 1.0, 1.0], [0.0,  0.0,  1.]])\n",
    "A_2 = jnp.array([[1.0, 1.0], [1., 0.]])\n",
    "\n",
    "A_tensor = A_1[..., None] * A_2[:, None]\n",
    "\n",
    "A_tensor /= A_tensor.sum(0)\n",
    "\n",
    "A = [jnp.broadcast_to(A_tensor, (n_batch, num_obs[0], 3, 2)) ]\n",
    "\n",
    "# create two transition matrices, one for each state factor\n",
    "B_1 = jnp.broadcast_to(\n",
    "    jnp.array([[0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0]]), (n_batch, 3, 3)\n",
    ")\n",
    "\n",
    "B_2 = jnp.broadcast_to(\n",
    "        jnp.array([[0.0, 1.0], [1.0, 0.0]]), (n_batch, 2, 2)\n",
    "    )\n",
    "\n",
    "B = [B_1[..., None], B_2[..., None]]\n",
    "\n",
    "# for the single modality, a sequence over time of observations (one hot vectors)\n",
    "obs = [jnp.broadcast_to(jnp.array([[1., 0.], # observation 0 is ambiguous with respect state factors\n",
    "                                    [1., 0], # observation 0 is ambiguous with respect state factors\n",
    "                                    [1., 0], # observation 0 is ambiguous with respect state factors\n",
    "                                    [0., 1.]])[:, None], (4, n_batch, num_obs[0]) )] # observation 1 provides information about exact state of both factors \n",
    "C = [jnp.zeros((n_batch, num_obs[0]))] # flat preferences\n",
    "D = [jnp.ones((n_batch, 3)) / 3., jnp.ones((n_batch, 2)) / 2.] # flat prior\n",
    "E = jnp.ones((n_batch, 1))\n",
    "\n",
    "pA = None\n",
    "pB = None\n",
    "\n",
    "agent = Agent(\n",
    "        A=A,\n",
    "        B=B,\n",
    "        C=C,\n",
    "        D=D,\n",
    "        E=E,\n",
    "        pA=pA,\n",
    "        pB=pB,\n",
    "        policy_len=3,\n",
    "        onehot_obs=True,\n",
    "        action_selection=\"deterministic\",\n",
    "        sampling_mode=\"full\",\n",
    "        inference_algo=\"ovf\",\n",
    "        num_iter=16\n",
    ")\n",
    "\n",
    "\n",
    "prior = agent.D\n",
    "action_hist = []\n",
    "qs_hist=None\n",
    "first_obs = jtu.tree_map(lambda x: jnp.moveaxis(x[:2], 0, 1), obs)\n",
    "curr_obs = jtu.tree_map(lambda x: x[-1], first_obs)\n",
    "\n",
    "\n",
    "infer_states = partial(\n",
    "        run_factorized_fpi,\n",
    "        A_dependencies=agent.A_dependencies,\n",
    "        num_iter=16\n",
    "    )\n",
    "    \n",
    "output = vmap(infer_states)(\n",
    "        agent.A,\n",
    "        curr_obs,\n",
    "        prior\n",
    "    )\n",
    "\n",
    "print(\"Inputs\")\n",
    "print(\"A\", agent.A)\n",
    "print(\"obs\", curr_obs)\n",
    "print(\"D\", prior)\n",
    "print(\"A_dep\", agent.A_dependencies)\n",
    "\n",
    "print(\"output\")\n",
    "print(output)\n",
    "\n",
    "#[Array([[0.36628395, 0.36628395, 0.2674321 ],\n",
    "#       [0.36628395, 0.36628395, 0.2674321 ]], dtype=float32), Array([[0.45378983, 0.5462102 ],\n",
    "#       [0.45378983, 0.5462102 ]], dtype=float32)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4093924d-2fb7-42dd-8e12-fe0591d02eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average latency: 36.29 ms\n",
      "Standard deviation: 11.98 ms\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Run the model 1k times and measure the latency\n",
    "latencies = []\n",
    "outputs = []\n",
    "for _ in range(1000):\n",
    "    start_time = time.time()\n",
    "    output = vmap(infer_states)(\n",
    "        agent.A,\n",
    "        curr_obs,\n",
    "        prior\n",
    "    )\n",
    "    #outputs.append(output)\n",
    "    latency = time.time() - start_time\n",
    "    latencies.append(latency)\n",
    "\n",
    "# Calculate average latency and standard deviation\n",
    "average_latency = np.mean(latencies)\n",
    "std_latency = np.std(latencies)\n",
    "\n",
    "print(f\"Average latency: {average_latency * 1000:.2f} ms\")\n",
    "print(f\"Standard deviation: {std_latency * 1000:.2f} ms\")\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c160e9a9-a658-4077-bc4a-cef412ce7b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average latency: 0.44 ms\n",
      "Standard deviation: 0.72 ms\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "jf = jit(top_function)\n",
    "# Compile (warm up)\n",
    "jf(agent.A, curr_obs, prior, agent.A_dependencies, 16)\n",
    "\n",
    "latencies = []\n",
    "outputs = []\n",
    "for _ in range(100000):\n",
    "    start_time = time.time()\n",
    "    y = jf(agent.A, curr_obs, prior, agent.A_dependencies, 16)\n",
    "    # If y is a list, block until all elements are ready\n",
    "    if isinstance(y, list):\n",
    "        for elem in y:\n",
    "            elem.block_until_ready()\n",
    "    else:\n",
    "        y.block_until_ready()\n",
    "    #outputs.append(output)\n",
    "    latency = time.time() - start_time\n",
    "    latencies.append(latency)\n",
    "\n",
    "# Calculate average latency and standard deviation\n",
    "average_latency = np.mean(latencies)\n",
    "std_latency = np.std(latencies)\n",
    "\n",
    "print(f\"Average latency: {average_latency * 1000:.2f} ms\")\n",
    "print(f\"Standard deviation: {std_latency * 1000:.2f} ms\")\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63a9f84-396b-4c3d-93c9-a660e8f1ec33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
