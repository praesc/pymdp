{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdfa3eb4-1758-4634-b398-cdc3c4c5d7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example successfully demonstrates the conversion of JAX functions to TensorFlow and subsequently to ONNX, \n",
    "# using TensorFlow's tf2onnx tool for ONNX export and ONNX Runtime for inference. \n",
    "\n",
    "from jax.experimental import jax2tf\n",
    "from jax import numpy as jnp\n",
    "from jax import tree_util as jtu, vmap, jit, lax, nn\n",
    "from jax.experimental import sparse\n",
    "\n",
    "from pymdp.jax.agent import Agent\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from functools import partial\n",
    "from typing import Optional, Tuple, List\n",
    "\n",
    "import onnx\n",
    "import tf2onnx\n",
    "import onnxruntime as ort\n",
    "import netron\n",
    "import time\n",
    "\n",
    "from opt_einsum import contract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24b46f73-a24a-4843-93e8-f884f9f691de",
   "metadata": {},
   "outputs": [],
   "source": [
    "MINVAL = jnp.finfo(float).eps\n",
    "\n",
    "def log_stable(x):\n",
    "    return jnp.log(jnp.clip(x, min=MINVAL))\n",
    "\n",
    "def add(x, y):\n",
    "    return x + y\n",
    "\n",
    "def compute_log_likelihood_single_modality(o_m, A_m, distr_obs=True):\n",
    "    \"\"\" Compute observation likelihood for a single modality (observation and likelihood)\"\"\"\n",
    "    if distr_obs: \n",
    "        expanded_obs = jnp.expand_dims(o_m, tuple(range(1, A_m.ndim)))\n",
    "        likelihood = (expanded_obs * A_m).sum(axis=0)\n",
    "    else: \n",
    "        likelihood = A_m[o_m] \n",
    "    \n",
    "    return log_stable(likelihood)\n",
    "\n",
    "def compute_log_likelihood_per_modality(obs, A, distr_obs=True):\n",
    "    \"\"\" Compute likelihood over hidden states across observations from different modalities, and return them per modality \"\"\"\n",
    "    ll_all = jtu.tree_map(lambda o, a: compute_log_likelihood_single_modality(o, a, distr_obs=distr_obs), obs, A)\n",
    "            \n",
    "    return ll_all\n",
    "\n",
    "def marginal_log_likelihood(qs, log_likelihood, i):\n",
    "    xs = [q for j, q in enumerate(qs) if j != i]\n",
    "    return factor_dot(log_likelihood, xs, keep_dims=(i,))\n",
    "\n",
    "\n",
    "@partial(jit, static_argnames=['keep_dims'])\n",
    "def factor_dot(M, xs, keep_dims: Optional[Tuple[int]] = None):\n",
    "    \"\"\" Dot product of a multidimensional array with `x`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    - `qs` [list of 1D numpy.ndarray] - list of jnp.ndarrays\n",
    "    \n",
    "    Returns \n",
    "    -------\n",
    "    - `Y` [1D numpy.ndarray] - the result of the dot product\n",
    "    \"\"\"\n",
    "    d = len(keep_dims) if keep_dims is not None else 0\n",
    "    assert M.ndim == len(xs) + d\n",
    "    keep_dims = () if keep_dims is None else keep_dims\n",
    "    dims = tuple((i,) for i in range(M.ndim) if i not in keep_dims)\n",
    "    return factor_dot_flex(M, xs, dims, keep_dims=keep_dims)\n",
    "\n",
    "@partial(jit, static_argnames=['dims', 'keep_dims'])\n",
    "def factor_dot_flex(M, xs, dims: List[Tuple[int]], keep_dims: Optional[Tuple[int]] = None):\n",
    "    \"\"\" Dot product of a multidimensional array with `x`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    - `M` [numpy.ndarray] - tensor\n",
    "    - 'xs' [list of numpyr.ndarray] - list of tensors\n",
    "    - 'dims' [list of tuples] - list of dimensions of xs tensors in tensor M\n",
    "    - 'keep_dims' [tuple] - tuple of integers denoting dimesions to keep\n",
    "    Returns \n",
    "    -------\n",
    "    - `Y` [1D numpy.ndarray] - the result of the dot product\n",
    "    \"\"\"\n",
    "    all_dims = tuple(range(M.ndim))\n",
    "    matrix = [[xs[f], dims[f]] for f in range(len(xs))]\n",
    "    args = [M, all_dims]\n",
    "    for row in matrix:\n",
    "        args.extend(row)\n",
    "\n",
    "    args += [keep_dims]\n",
    "    return contract(*args, backend='jax')\n",
    "\n",
    "def mll_factors(qs, ll_m, factor_list_m) -> List:\n",
    "    relevant_factors = [qs[f] for f in factor_list_m]\n",
    "        \n",
    "    marginal_ll_f = jtu.Partial(marginal_log_likelihood, relevant_factors, ll_m)\n",
    "    loc_nf = len(factor_list_m)\n",
    "    loc_factors = list(range(loc_nf))\n",
    "    return jtu.tree_map(marginal_ll_f, loc_factors)\n",
    "\n",
    "\n",
    "def all_marginal_log_likelihood(qs, log_likelihoods, all_factor_lists):\n",
    "    qL_marginals = jtu.tree_map(lambda ll_m, factor_list_m: mll_factors(qs, ll_m, factor_list_m), log_likelihoods, all_factor_lists)\n",
    "    \n",
    "    num_factors = len(qs)\n",
    "\n",
    "    # instead of a double loop we could have a list defining m to f mapping\n",
    "    # which could be resolved with a single tree_map cast\n",
    "    qL_all = [jnp.zeros(1)] * num_factors\n",
    "    for m, factor_list_m in enumerate(all_factor_lists):\n",
    "        for l, f in enumerate(factor_list_m):\n",
    "            qL_all[f] += qL_marginals[m][l]\n",
    "\n",
    "    return qL_all\n",
    "\n",
    "def run_factorized_fpi(A, obs, prior, A_dependencies, num_iter=1):\n",
    "    \"\"\"\n",
    "    Run the fixed point iteration algorithm with sparse dependencies between factors and outcomes (stored in `A_dependencies`)\n",
    "    \"\"\"\n",
    "    # Step 1: Compute log likelihoods for each factor\n",
    "    ############# ad-hoc adaptation convert log_likelihoods as a list\n",
    "    log_likelihoods = [compute_log_likelihood_per_modality(obs, A)]\n",
    "    \n",
    "    # Step 2: Map prior to log space and create initial log-posterior\n",
    "    log_prior = jtu.tree_map(log_stable, prior)\n",
    "    log_q = jtu.tree_map(jnp.zeros_like, prior)\n",
    "\n",
    "    # Step 3: Iterate until convergence\n",
    "    def scan_fn(carry, t):\n",
    "        log_q = carry\n",
    "        q = jtu.tree_map(nn.softmax, log_q)\n",
    "        marginal_ll = all_marginal_log_likelihood(q, log_likelihoods, A_dependencies)\n",
    "        log_q = jtu.tree_map(add, marginal_ll, log_prior)\n",
    "\n",
    "        return log_q, None\n",
    "   \n",
    "    res, _ = lax.scan(scan_fn, log_q, jnp.zeros(16))\n",
    "\n",
    "    # Step 4: Map result to factorised posterior\n",
    "    qs = jtu.tree_map(nn.softmax, res)\n",
    "    return qs\n",
    "\n",
    "def top_function(A, obs, prior):# A_dependencies, num_iter=1):\n",
    "    infer_states = partial(\n",
    "        run_factorized_fpi,\n",
    "        A_dependencies=[[0,1]], ## ad-hoc traced arrays give problem when indexing lists\n",
    "        num_iter=16 ## ad-hoc\n",
    "    )\n",
    "    \n",
    "    output = vmap(infer_states)(\n",
    "    A,\n",
    "    obs,\n",
    "    prior\n",
    "    )\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd9d9064-08ab-4adb-acbd-4eb6e7be3413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simplified model saved at: path_to_simplified_model.onnx\n",
      "Serving 'path_to_simplified_model.onnx' at http://localhost:21771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('localhost', 21771)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert JAX function to TF\n",
    "top_function_tf = jax2tf.convert(top_function, enable_xla=False)\n",
    "# Create a TF graph out of the TF function\n",
    "function_graph = tf.function(top_function_tf, autograph=False)\n",
    "\n",
    "# Export the model to ONNX\n",
    "input_signature = [\n",
    "        tf.TensorSpec(shape=(2, 2, 3, 2), dtype=tf.float32), # A tensor\n",
    "        #[tf.TensorSpec(shape=(2, 3, 2), dtype=tf.float32)], # A tensor\n",
    "        tf.TensorSpec(shape=(2, 2), dtype=tf.float32),       # obs\n",
    "        [                                                    # Prior\n",
    "            tf.TensorSpec(shape=[2, 3], dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=[2, 2], dtype=tf.float32)\n",
    "        ]\n",
    "        #[tf.TensorSpec(shape=[2], dtype=tf.int32)],      # A_dependencies\n",
    "        #tf.TensorSpec(shape=(1), dtype=tf.bool)           # Iter\n",
    "    ]\n",
    "\n",
    "# Export the module to ONNX\n",
    "inference_onnx, _ = tf2onnx.convert.from_function(\n",
    "    function_graph,\n",
    "    input_signature=input_signature,\n",
    "    opset=13\n",
    ")\n",
    "\n",
    "onnx_model_path = \"trial.onnx\"\n",
    "with open(onnx_model_path, \"wb\") as f:\n",
    "    f.write(inference_onnx.SerializeToString())\n",
    "\n",
    "from onnxsim import simplify\n",
    "\n",
    "# Load your ONNX model\n",
    "model = onnx.load(onnx_model_path)\n",
    "\n",
    "# Simplify the model\n",
    "model_simp, check = simplify(model)\n",
    "\n",
    "# Ensure the simplified model is valid\n",
    "assert check, \"Simplified ONNX model could not be validated\"\n",
    "\n",
    "# Save the simplified model\n",
    "simplified_model_path = \"path_to_simplified_model.onnx\"\n",
    "onnx.save(model_simp, simplified_model_path)\n",
    "\n",
    "print(f\"Simplified model saved at: {simplified_model_path}\")\n",
    "\n",
    "netron.start(simplified_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f560f8be-e331-4876-9555-c72d423d2077",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_states = [3, 2]\n",
    "num_obs = [2]\n",
    "n_batch = 2\n",
    "\n",
    "A_1 = np.array([[1.0, 1.0, 1.0], [0.0,  0.0,  1.]])\n",
    "A_2 = np.array([[1.0, 1.0], [1., 0.]])\n",
    "\n",
    "A_tensor = A_1[..., None] * A_2[:, None]\n",
    "\n",
    "A_tensor /= A_tensor.sum(0)\n",
    "\n",
    "# Add-hoc, not list\n",
    "A = np.broadcast_to(A_tensor, (n_batch, num_obs[0], 3, 2))\n",
    "\n",
    "# create two transition matrices, one for each state factor\n",
    "B_1 = np.broadcast_to(\n",
    "    np.array([[0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0]]), (n_batch, 3, 3)\n",
    ")\n",
    "\n",
    "B_2 = np.broadcast_to(\n",
    "        np.array([[0.0, 1.0], [1.0, 0.0]]), (n_batch, 2, 2)\n",
    "    )\n",
    "\n",
    "B = [B_1[..., None], B_2[..., None]]\n",
    "\n",
    "# for the single modality, a sequence over time of observations (one hot vectors)\n",
    "obs = [np.broadcast_to(np.array([[1., 0.], # observation 0 is ambiguous with respect state factors\n",
    "                                    [1., 0], # observation 0 is ambiguous with respect state factors\n",
    "                                    [1., 0], # observation 0 is ambiguous with respect state factors\n",
    "                                    [0., 1.]])[:, None], (4, n_batch, num_obs[0]) )] # observation 1 provides information about exact state of both factors \n",
    "C = [np.zeros((n_batch, num_obs[0]))] # flat preferences\n",
    "D = [np.ones((n_batch, 3)) / 3., np.ones((n_batch, 2)) / 2.] # flat prior\n",
    "E = np.ones((n_batch, 1))\n",
    "\n",
    "curr_obs = jtu.tree_map(lambda x: np.moveaxis(x[:1], 0, 1), obs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13139359-e3a6-4b38-833c-b52df818ff8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs\n",
      "A [[[[1.  1. ]\n",
      "   [1.  1. ]\n",
      "   [0.5 1. ]]\n",
      "\n",
      "  [[0.  0. ]\n",
      "   [0.  0. ]\n",
      "   [0.5 0. ]]]\n",
      "\n",
      "\n",
      " [[[1.  1. ]\n",
      "   [1.  1. ]\n",
      "   [0.5 1. ]]\n",
      "\n",
      "  [[0.  0. ]\n",
      "   [0.  0. ]\n",
      "   [0.5 0. ]]]]\n",
      "Obs [[1. 0.]\n",
      " [1. 0.]]\n",
      "Prior 0 [[0.33333334 0.33333334 0.33333334]\n",
      " [0.33333334 0.33333334 0.33333334]]\n",
      "Prior 1 [[0.5 0.5]\n",
      " [0.5 0.5]]\n",
      "Output from ONNX Runtime:\n",
      "[array([[0.36628395, 0.36628395, 0.2674321 ],\n",
      "       [0.36628395, 0.36628395, 0.2674321 ]], dtype=float32), array([[0.45378983, 0.5462102 ],\n",
      "       [0.45378983, 0.5462102 ]], dtype=float32)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;93m2024-07-31 11:14:11.688623 [W:onnxruntime:, graph.cc:4093 CleanUnusedInitializersAndNodeArgs] Removing initializer '_v_92'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2024-07-31 11:14:11.688699 [W:onnxruntime:, graph.cc:4093 CleanUnusedInitializersAndNodeArgs] Removing initializer '_v_90'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2024-07-31 11:14:11.688717 [W:onnxruntime:, graph.cc:4093 CleanUnusedInitializersAndNodeArgs] Removing initializer 'Reshape__96_shape__111'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2024-07-31 11:14:11.688746 [W:onnxruntime:, graph.cc:4093 CleanUnusedInitializersAndNodeArgs] Removing initializer 'Reshape__97_shape__112'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2024-07-31 11:14:11.688766 [W:onnxruntime:, graph.cc:4093 CleanUnusedInitializersAndNodeArgs] Removing initializer 'const_fold_opt__70'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2024-07-31 11:14:11.688779 [W:onnxruntime:, graph.cc:4093 CleanUnusedInitializersAndNodeArgs] Removing initializer 'const_fold_opt__71'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2024-07-31 11:14:11.688803 [W:onnxruntime:, graph.cc:4093 CleanUnusedInitializersAndNodeArgs] Removing initializer 'const_fold_opt__74'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2024-07-31 11:14:11.688815 [W:onnxruntime:, graph.cc:4093 CleanUnusedInitializersAndNodeArgs] Removing initializer 'einsum13494261328_ba_batch_axes__77'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2024-07-31 11:14:11.688833 [W:onnxruntime:, graph.cc:4093 CleanUnusedInitializersAndNodeArgs] Removing initializer 'const_fold_opt__63'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2024-07-31 11:14:11.688845 [W:onnxruntime:, graph.cc:4093 CleanUnusedInitializersAndNodeArgs] Removing initializer 'einsum13494261328_ba_right_set__80'. It is not used by any node and should be removed from the model.\u001b[m\n"
     ]
    }
   ],
   "source": [
    "# Load the ONNX model with ONNX Runtime\n",
    "ort_session = ort.InferenceSession(simplified_model_path)\n",
    "\n",
    "# Get model input details\n",
    "input_names = [input.name for input in ort_session.get_inputs()]\n",
    "\n",
    "# Prepare the inputs\n",
    "# Assuming the model expects two inputs, input1 and input2\n",
    "# Create input dictionary\n",
    "obs = np.squeeze(curr_obs[0], axis=1)\n",
    "\n",
    "inputs = {\n",
    "    input_names[0]: A.astype(np.float32),\n",
    "    input_names[1]: np.squeeze(curr_obs[0], axis=1).astype(np.float32),\n",
    "    input_names[2]: D[0].astype(np.float32),\n",
    "    input_names[3]: D[1].astype(np.float32)\n",
    "    #input_names[4]: [[0, 1]],\n",
    "    #input_names[5]: 1\n",
    "}\n",
    "\n",
    "# Run the model\n",
    "output_names = [output.name for output in ort_session.get_outputs()]\n",
    "outputs = ort_session.run(output_names, inputs)\n",
    "\n",
    "print(\"Inputs\")\n",
    "print(\"A\", A.astype(np.float32))\n",
    "print(\"Obs\", np.squeeze(curr_obs[0], axis=1).astype(np.float32))\n",
    "print(\"Prior 0\", D[0].astype(np.float32))\n",
    "print(\"Prior 1\", D[1].astype(np.float32))\n",
    "\n",
    "print(\"Output from ONNX Runtime:\")\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a587423-2f8f-4cc5-9de1-afed95ee9ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average latency: 1.70 ms\n",
      "Standard deviation: 1.26 ms\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Run the model 1k times and measure the latency\n",
    "latencies = []\n",
    "outputs = []\n",
    "for _ in range(100000):\n",
    "    start_time = time.time()\n",
    "    output = ort_session.run(output_names, inputs)\n",
    "    #outputs.append(output)\n",
    "    \n",
    "    latency = time.time() - start_time\n",
    "    latencies.append(latency)\n",
    "\n",
    "# Calculate average latency and standard deviation\n",
    "average_latency = np.mean(latencies)\n",
    "std_latency = np.std(latencies)\n",
    "\n",
    "print(f\"Average latency: {average_latency * 1000:.2f} ms\")\n",
    "print(f\"Standard deviation: {std_latency * 1000:.2f} ms\")\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36b0989-dbee-4bf9-841a-0fae260ee66d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
